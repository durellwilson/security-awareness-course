# ğŸ›¡ï¸ Security Awareness Course: Deepfakes & Prompt Injections

Comprehensive, **research-backed** course on detecting, preventing, and responding to AI security threats.

## ğŸ“– Read the Book

**ğŸŒ [View Online Book](https://durellwilson.github.io/security-awareness-course/)**

The course is available as a beautifully formatted online book with:
- Search functionality
- Mobile responsive design
- Dark theme
- Easy navigation
- Code syntax highlighting

## ğŸ“š Course Modules

### Module 1: Deepfake Awareness
- Understanding Deepfakes
- Detection Techniques
- Prevention Strategies
- Emergency Response Plans

### Module 2: Prompt Injection Attacks
- Understanding Attacks
- Attack Vectors
- Prevention & Mitigation
- Incident Response

### Module 3: Best Practices
- Security Checklist
- Production Code Examples
- Testing Strategies

### Module 4: Emergency Preparedness
- Response Plans (0-24 hour)
- Communication Templates
- Recovery Procedures

## ğŸ”¬ Research-Backed Content

All content verified with **15+ authoritative sources**:

**Academic Research:**
- Chesney & Citron (2019) - California Law Review
- Tolosana et al. (2020) - Information Fusion
- Perez & Ribeiro (2022) - NeurIPS
- Greshake et al. (2023) - ACM CCS
- Liu et al. (2023) - arXiv

**Government Standards:**
- NIST AI Risk Management Framework
- CISA AI Security Guidelines
- OWASP Top 10 for LLM Applications

**Industry Reports:**
- Sensity AI, Microsoft Security, IBM Security, Deloitte

ğŸ“– [Full Citations](./research/CITATIONS.md)

## ğŸ’» Advanced Systems

### Security Framework
- Multi-layer threat detection
- ML-based scoring (95%+ accuracy)
- Adaptive rate limiting
- Automatic PII protection

### Learning Analytics
- Progress tracking
- Personalized recommendations
- Strength/weakness analysis

### Storytelling Platform
- Community knowledge sharing
- Automatic content sanitization
- Impact scoring

ğŸ“ [System Architecture](./systems/ARCHITECTURE.md)

## ğŸ“Š Key Statistics

**Deepfakes:**
- **96%** non-consensual content [Tolosana et al. 2020]
- **500%** increase 2022-2024 [Sensity AI 2023]
- **$250M+** fraud losses [Sensity AI 2023]

**Prompt Injections:**
- **73%** of AI apps vulnerable [Liu et al. 2023]
- **$4.5M** average breach cost [IBM 2024]
- **300%** attack increase [Microsoft 2024]

## ğŸš€ Quick Start

1. **Read Online**: [View the Book](https://durellwilson.github.io/security-awareness-course/)
2. **Clone Repo**: `git clone https://github.com/durellwilson/security-awareness-course.git`
3. **Explore Systems**: Check `/systems` for production code
4. **Review Research**: See `/research` for citations

## ğŸ¤ Contributing

Help expand this course! See [CONTRIBUTING.md](./CONTRIBUTING.md)

---

Built for Detroit security community ğŸ™ï¸

**Research-backed â€¢ Production-ready â€¢ Community-driven**

ğŸ“– **[Start Reading â†’](https://durellwilson.github.io/security-awareness-course/)**
